{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1643560b",
   "metadata": {},
   "source": [
    "# üß† Deep Sector Rotation Swing Trading Notebook\n",
    "\n",
    "This notebook implements a weekly ETF sector rotation strategy inspired by the paper:\n",
    "\n",
    "**\"Deep Sector Rotation Swing Trading\"** (Bock & Maewal, SSRN #4280640)\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Strategy Summary:\n",
    "- Trades once per week (Buy on Monday open, Sell on Friday close)\n",
    "- Uses a deep learning model to predict next-week returns for selected ETFs\n",
    "- Selects high-confidence trades using Monte Carlo Dropout\n",
    "- Allocates capital selectively based on prediction strength\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Key Components:\n",
    "- Weekly ETF price data (e.g., XLK, XLF, XLV‚Ä¶)\n",
    "- Rolling technical and macro features\n",
    "- Multi-output regression model\n",
    "- Weekly backtest with position logging and performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36deb115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Downloading data from 2020-04-25 to 2025-04-19\n",
      "‚¨áÔ∏è Downloading XLK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLF...\n",
      "‚¨áÔ∏è Downloading XLV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLE...\n",
      "‚¨áÔ∏è Downloading XLI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLP...\n",
      "‚¨áÔ∏è Downloading XLRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading XLC...\n",
      "‚¨áÔ∏è Downloading SOXX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading SH...\n",
      "‚¨áÔ∏è Downloading DOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading RWM...\n",
      "‚¨áÔ∏è Downloading ITA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading JETS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading QQQ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading VOO...\n",
      "‚úÖ Saved: etf_prices_weekly.csv\n",
      "‚úÖ Saved: etf_volume_weekly.csv\n",
      "‚úÖ Saved: etf_high_weekly.csv\n",
      "‚úÖ Saved: etf_low_weekly.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLF</th>\n",
       "      <th>XLV</th>\n",
       "      <th>XLE</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLRE</th>\n",
       "      <th>XLU</th>\n",
       "      <th>XLB</th>\n",
       "      <th>XLC</th>\n",
       "      <th>SOXX</th>\n",
       "      <th>SH</th>\n",
       "      <th>DOG</th>\n",
       "      <th>RWM</th>\n",
       "      <th>ITA</th>\n",
       "      <th>JETS</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLF</th>\n",
       "      <th>XLV</th>\n",
       "      <th>XLE</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLRE</th>\n",
       "      <th>XLU</th>\n",
       "      <th>XLB</th>\n",
       "      <th>XLC</th>\n",
       "      <th>SOXX</th>\n",
       "      <th>SH</th>\n",
       "      <th>DOG</th>\n",
       "      <th>RWM</th>\n",
       "      <th>ITA</th>\n",
       "      <th>JETS</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>85.254005</td>\n",
       "      <td>20.092381</td>\n",
       "      <td>90.433411</td>\n",
       "      <td>29.169212</td>\n",
       "      <td>57.577568</td>\n",
       "      <td>107.764603</td>\n",
       "      <td>50.507130</td>\n",
       "      <td>27.815893</td>\n",
       "      <td>47.784370</td>\n",
       "      <td>45.973640</td>\n",
       "      <td>47.360298</td>\n",
       "      <td>71.331718</td>\n",
       "      <td>95.017853</td>\n",
       "      <td>47.620911</td>\n",
       "      <td>38.178116</td>\n",
       "      <td>71.822189</td>\n",
       "      <td>13.990602</td>\n",
       "      <td>206.453033</td>\n",
       "      <td>240.694519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>90.892845</td>\n",
       "      <td>20.301870</td>\n",
       "      <td>91.893959</td>\n",
       "      <td>31.553192</td>\n",
       "      <td>58.354267</td>\n",
       "      <td>112.584442</td>\n",
       "      <td>50.945415</td>\n",
       "      <td>28.213499</td>\n",
       "      <td>48.023800</td>\n",
       "      <td>47.503380</td>\n",
       "      <td>49.538235</td>\n",
       "      <td>76.902252</td>\n",
       "      <td>91.726860</td>\n",
       "      <td>46.390877</td>\n",
       "      <td>36.040718</td>\n",
       "      <td>72.466820</td>\n",
       "      <td>13.543777</td>\n",
       "      <td>218.214890</td>\n",
       "      <td>248.995010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>89.636581</td>\n",
       "      <td>19.172464</td>\n",
       "      <td>92.827560</td>\n",
       "      <td>29.283113</td>\n",
       "      <td>54.979321</td>\n",
       "      <td>110.875420</td>\n",
       "      <td>50.305531</td>\n",
       "      <td>26.208521</td>\n",
       "      <td>46.869385</td>\n",
       "      <td>46.046059</td>\n",
       "      <td>48.955540</td>\n",
       "      <td>73.753281</td>\n",
       "      <td>93.678497</td>\n",
       "      <td>47.549076</td>\n",
       "      <td>38.035030</td>\n",
       "      <td>67.185555</td>\n",
       "      <td>11.915346</td>\n",
       "      <td>216.671875</td>\n",
       "      <td>243.677567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-18</th>\n",
       "      <td>92.532722</td>\n",
       "      <td>19.964867</td>\n",
       "      <td>92.088089</td>\n",
       "      <td>31.309097</td>\n",
       "      <td>59.029266</td>\n",
       "      <td>116.396141</td>\n",
       "      <td>50.375648</td>\n",
       "      <td>27.663614</td>\n",
       "      <td>48.297432</td>\n",
       "      <td>47.910706</td>\n",
       "      <td>51.305408</td>\n",
       "      <td>78.060364</td>\n",
       "      <td>90.578842</td>\n",
       "      <td>45.879112</td>\n",
       "      <td>35.083809</td>\n",
       "      <td>73.063698</td>\n",
       "      <td>13.603354</td>\n",
       "      <td>222.873016</td>\n",
       "      <td>251.561127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-25</th>\n",
       "      <td>93.952026</td>\n",
       "      <td>21.321968</td>\n",
       "      <td>95.221764</td>\n",
       "      <td>31.536917</td>\n",
       "      <td>62.570652</td>\n",
       "      <td>119.238106</td>\n",
       "      <td>51.918388</td>\n",
       "      <td>29.313278</td>\n",
       "      <td>51.042381</td>\n",
       "      <td>50.191738</td>\n",
       "      <td>51.601532</td>\n",
       "      <td>80.354279</td>\n",
       "      <td>87.938385</td>\n",
       "      <td>44.146301</td>\n",
       "      <td>34.001686</td>\n",
       "      <td>78.574165</td>\n",
       "      <td>14.983549</td>\n",
       "      <td>226.463684</td>\n",
       "      <td>259.157532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price             XLK        XLF        XLV        XLE        XLI         XLY  \\\n",
       "Ticker            XLK        XLF        XLV        XLE        XLI         XLY   \n",
       "Date                                                                            \n",
       "2020-04-27  85.254005  20.092381  90.433411  29.169212  57.577568  107.764603   \n",
       "2020-05-04  90.892845  20.301870  91.893959  31.553192  58.354267  112.584442   \n",
       "2020-05-11  89.636581  19.172464  92.827560  29.283113  54.979321  110.875420   \n",
       "2020-05-18  92.532722  19.964867  92.088089  31.309097  59.029266  116.396141   \n",
       "2020-05-25  93.952026  21.321968  95.221764  31.536917  62.570652  119.238106   \n",
       "\n",
       "Price             XLP       XLRE        XLU        XLB        XLC       SOXX  \\\n",
       "Ticker            XLP       XLRE        XLU        XLB        XLC       SOXX   \n",
       "Date                                                                           \n",
       "2020-04-27  50.507130  27.815893  47.784370  45.973640  47.360298  71.331718   \n",
       "2020-05-04  50.945415  28.213499  48.023800  47.503380  49.538235  76.902252   \n",
       "2020-05-11  50.305531  26.208521  46.869385  46.046059  48.955540  73.753281   \n",
       "2020-05-18  50.375648  27.663614  48.297432  47.910706  51.305408  78.060364   \n",
       "2020-05-25  51.918388  29.313278  51.042381  50.191738  51.601532  80.354279   \n",
       "\n",
       "Price              SH        DOG        RWM        ITA       JETS         QQQ  \\\n",
       "Ticker             SH        DOG        RWM        ITA       JETS         QQQ   \n",
       "Date                                                                            \n",
       "2020-04-27  95.017853  47.620911  38.178116  71.822189  13.990602  206.453033   \n",
       "2020-05-04  91.726860  46.390877  36.040718  72.466820  13.543777  218.214890   \n",
       "2020-05-11  93.678497  47.549076  38.035030  67.185555  11.915346  216.671875   \n",
       "2020-05-18  90.578842  45.879112  35.083809  73.063698  13.603354  222.873016   \n",
       "2020-05-25  87.938385  44.146301  34.001686  78.574165  14.983549  226.463684   \n",
       "\n",
       "Price              VOO  \n",
       "Ticker             VOO  \n",
       "Date                    \n",
       "2020-04-27  240.694519  \n",
       "2020-05-04  248.995010  \n",
       "2020-05-11  243.677567  \n",
       "2020-05-18  251.561127  \n",
       "2020-05-25  259.157532  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF list\n",
    "etf_list = [\n",
    "    'XLK', 'XLF', 'XLV', 'XLE', 'XLI', 'XLY', 'XLP', 'XLRE', 'XLU', 'XLB', 'XLC',\n",
    "    'SOXX', 'SH', 'DOG', 'RWM', 'ITA', 'JETS', 'QQQ', 'VOO'\n",
    "]\n",
    "\n",
    "# Date range\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(weeks=5*52)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"üìÖ Downloading data from {start_date} to {end_date}\")\n",
    "\n",
    "# Ensure dataset/ exists\n",
    "dataset_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'dataset'))\n",
    "if not os.path.isdir(dataset_path):\n",
    "    raise FileNotFoundError(f\"üö´ 'dataset/' folder not found at {dataset_path}\")\n",
    "\n",
    "# Containers\n",
    "adjclose_data, volume_data, high_data, low_data = {}, {}, {}, {}\n",
    "\n",
    "# Download each ETF\n",
    "for symbol in etf_list:\n",
    "    print(f\"‚¨áÔ∏è Downloading {symbol}...\")\n",
    "    data = yf.download(symbol, start=start_date, end=end_date, interval='1wk', auto_adjust=False)\n",
    "    if not data.empty:\n",
    "        adjclose_data[symbol] = data[['Adj Close']].rename(columns={'Adj Close': symbol})\n",
    "        volume_data[symbol] = data[['Volume']].rename(columns={'Volume': symbol})\n",
    "        high_data[symbol] = data[['High']].rename(columns={'High': symbol})\n",
    "        low_data[symbol] = data[['Low']].rename(columns={'Low': symbol})\n",
    "\n",
    "# Merge and clean\n",
    "def combine_and_save(data_dict, filename):\n",
    "    df = pd.concat(data_dict.values(), axis=1)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df = df[~df.index.duplicated(keep='first')].sort_index()\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    path = os.path.join(dataset_path, filename)\n",
    "    df.to_csv(path)\n",
    "    print(f\"‚úÖ Saved: {filename}\")\n",
    "    return df\n",
    "\n",
    "# Save all\n",
    "price_df = combine_and_save(adjclose_data, 'etf_prices_weekly.csv')\n",
    "volume_df = combine_and_save(volume_data, 'etf_volume_weekly.csv')\n",
    "high_df = combine_and_save(high_data, 'etf_high_weekly.csv')\n",
    "low_df = combine_and_save(low_data, 'etf_low_weekly.csv')\n",
    "\n",
    "# Preview\n",
    "price_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d69954",
   "metadata": {},
   "source": [
    "### üåê Weekly Macro Indicator Download\n",
    "\n",
    "This section downloads weekly data for key macroeconomic signals that are used as input features for the model:\n",
    "\n",
    "| Indicator        | Source Symbol | Description |\n",
    "|------------------|---------------|-------------|\n",
    "| **VIX**          | `^VIX`        | CBOE Volatility Index (market fear gauge) |\n",
    "| **10Y Yield**    | `^TNX`        | 10-Year U.S. Treasury yield (interest rate proxy) |\n",
    "| **USD Index**    | `DX-Y.NYB`    | Strength of the U.S. dollar |\n",
    "| **Crude Oil**    | `CL=F`        | WTI Crude Oil futures price |\n",
    "\n",
    "All indicators are:\n",
    "- Downloaded at **weekly frequency** using Yahoo Finance\n",
    "- Aligned on the same date index as the ETF data\n",
    "- The 10-year yield is converted to a % by multiplying by `0.1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "43ce1960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VIX (^VIX)...\n",
      "Downloading 10Y_Yield (^TNX)...\n",
      "Downloading USD_Index (DX-Y.NYB)...\n",
      "Downloading WTI_Crude (CL=F)...\n",
      "‚úÖ Macro indicators saved to: c:\\Users\\lifeq\\Desktop\\QT_ETF_Rotate\\dataset\\macro_indicators_weekly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX</th>\n",
       "      <th>10Y_Yield</th>\n",
       "      <th>USD_Index</th>\n",
       "      <th>WTI_Crude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>37.189999</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>98.800003</td>\n",
       "      <td>19.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>27.980000</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>24.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>31.889999</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>100.400002</td>\n",
       "      <td>29.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-18</th>\n",
       "      <td>28.160000</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>99.860001</td>\n",
       "      <td>33.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-25</th>\n",
       "      <td>27.510000</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>98.339996</td>\n",
       "      <td>35.490002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VIX  10Y_Yield   USD_Index  WTI_Crude\n",
       "Date                                                   \n",
       "2020-04-27  37.189999     0.0642   98.800003  19.780001\n",
       "2020-05-04  27.980000     0.0682   99.730003  24.740000\n",
       "2020-05-11  31.889999     0.0640  100.400002  29.430000\n",
       "2020-05-18  28.160000     0.0657   99.860001  33.250000\n",
       "2020-05-25  27.510000     0.0648   98.339996  35.490002"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Macro indicator tickers on Yahoo Finance\n",
    "macro_tickers = {\n",
    "    'VIX': '^VIX',               # Volatility Index\n",
    "    '10Y_Yield': '^TNX',         # 10-Year Treasury Yield (multiply by 0.1)\n",
    "    'USD_Index': 'DX-Y.NYB',     # U.S. Dollar Index\n",
    "    'WTI_Crude': 'CL=F'          # Crude Oil (WTI)\n",
    "}\n",
    "\n",
    "# Date range matching your ETF backtest period\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(weeks=5*52)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Download weekly data\n",
    "macro_data = {}\n",
    "for name, ticker in macro_tickers.items():\n",
    "    print(f\"Downloading {name} ({ticker})...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval='1wk', auto_adjust=False)\n",
    "    macro_data[name] = data[['Close']].rename(columns={'Close': name})\n",
    "\n",
    "# Combine all macro indicators into one DataFrame\n",
    "macro_df = pd.concat(macro_data.values(), axis=1)\n",
    "\n",
    "# Fix 10Y yield scale\n",
    "if '10Y_Yield' in macro_df.columns:\n",
    "    macro_df['10Y_Yield'] = macro_df['10Y_Yield'] * 0.1\n",
    "\n",
    "# Drop missing rows\n",
    "macro_df.dropna(inplace=True)\n",
    "macro_df.columns = pd.Index(list(macro_tickers.keys()))\n",
    "\n",
    "# Save to CSV\n",
    "macro_save_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'dataset', 'macro_indicators_weekly.csv'))\n",
    "macro_df.to_csv(macro_save_path)\n",
    "print(f\"‚úÖ Macro indicators saved to: {macro_save_path}\")\n",
    "\n",
    "# Preview\n",
    "\n",
    "# macro_df = macro_df.apply(pd.to_numeric, errors='coerce')\n",
    "# macro_df.index = pd.to_datetime(macro_df.index)\n",
    "macro_df = macro_df[~macro_df.index.duplicated(keep='first')]\n",
    "macro_df.sort_index(inplace=True)\n",
    "macro_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02b9dd",
   "metadata": {},
   "source": [
    "### üß† Feature Engineering\n",
    "\n",
    "This section prepares input features for the machine learning model.\n",
    "\n",
    "#### üìà ETF-Specific Features:\n",
    "For each ETF, we will compute:\n",
    "- **1-week return**: Short-term price movement\n",
    "- **3-week return**: Medium-term trend\n",
    "- **6-week return**: Momentum across a longer window\n",
    "- **Streak**: Number of consecutive up weeks\n",
    "\n",
    "#### üåê Macro Indicators:\n",
    "From the macro_df, we already have:\n",
    "- **VIX**\n",
    "- **10Y Treasury Yield**\n",
    "- **USD Index**\n",
    "- **Crude Oil Price**\n",
    "\n",
    "These will be aligned with the ETF data by date and merged in.\n",
    "\n",
    "#### üì¶ Resulting Feature Matrix:\n",
    "For each ETF on each week:\n",
    "- One row = a snapshot of that ETF and macro environment\n",
    "- Target = the **next week's return** for that ETF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "39898fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature CSV with outlier clipping and edge flag saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# === Load datasets ===\n",
    "price_df = pd.read_csv('../dataset/etf_prices_weekly.csv', index_col=0)\n",
    "volume_df = pd.read_csv('../dataset/etf_volume_weekly.csv', index_col=0)\n",
    "high_df = pd.read_csv('../dataset/etf_high_weekly.csv', index_col=0)\n",
    "low_df = pd.read_csv('../dataset/etf_low_weekly.csv', index_col=0)\n",
    "\n",
    "# === Clean and convert ===\n",
    "for df in [price_df, volume_df, high_df, low_df]:\n",
    "    df[:] = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df.sort_index(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "# === Feature generation ===\n",
    "feature_rows = []\n",
    "\n",
    "for symbol in price_df.columns:\n",
    "    close = price_df[symbol]\n",
    "    high = high_df[symbol]\n",
    "    low = low_df[symbol]\n",
    "    volume = pd.to_numeric(volume_df[symbol], errors='coerce').replace(0, np.nan)\n",
    "\n",
    "    returns_1w = close.pct_change(1)\n",
    "    returns_3w = close.pct_change(3)\n",
    "    returns_6w = close.pct_change(6)\n",
    "    streak = (close.pct_change(1) > 0).astype(int).rolling(3).sum()\n",
    "\n",
    "    log_volume = np.log(volume)\n",
    "    log_volume_norm = log_volume / log_volume.rolling(5).mean()\n",
    "\n",
    "    shock_amplify_raw = (high - low) / close\n",
    "    shock_amplify = shock_amplify_raw.rolling(3).mean()\n",
    "    shock_amplify_1w = shock_amplify.shift(1)\n",
    "    shock_amplify_3w = shock_amplify.rolling(3).mean()\n",
    "    shock_delta = shock_amplify.diff()\n",
    "\n",
    "    vol_flag = (\n",
    "        shock_amplify_raw > (shock_amplify_raw.rolling(10).mean() +\n",
    "                             2 * shock_amplify_raw.rolling(10).std())\n",
    "    ).astype(int)\n",
    "\n",
    "    rsv = (close - low.rolling(9).min()) / (high.rolling(9).max() - low.rolling(9).min()) * 100\n",
    "    k = rsv.ewm(com=2).mean()\n",
    "    d = k.ewm(com=2).mean()\n",
    "\n",
    "    kd_signal = pd.Series(0, index=close.index)\n",
    "    kd_signal[(k < 30) & (d < 30)] = 1\n",
    "    kd_signal[(k > 70) & (d > 70)] = -1\n",
    "\n",
    "    ema12 = close.ewm(span=12).mean()\n",
    "    ema26 = close.ewm(span=26).mean()\n",
    "    macd = ema12 - ema26\n",
    "    macd_slope = macd.diff()\n",
    "\n",
    "    momentum_2w = close.pct_change(2)\n",
    "\n",
    "    kd_x_shock = kd_signal * shock_amplify_3w\n",
    "    streak_x_ret6 = streak * returns_6w\n",
    "\n",
    "    for i in range(len(close)):\n",
    "        date = close.index[i]\n",
    "        try:\n",
    "            nearest_macro_index = macro_df.index.get_indexer([date], method='nearest')[0]\n",
    "            macro_row = macro_df.iloc[nearest_macro_index]\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            'Date': date,\n",
    "            'ETF': symbol,\n",
    "            'Return_1w': returns_1w.iloc[i],\n",
    "            'Return_3w': returns_3w.iloc[i],\n",
    "            'Return_6w': returns_6w.iloc[i],\n",
    "            'Streak_Up': streak.iloc[i],\n",
    "            'LogVolumeNorm': log_volume_norm.iloc[i],\n",
    "            'Shock_Amplify': shock_amplify.iloc[i],\n",
    "            'Shock_Amplify_1w': shock_amplify_1w.iloc[i],\n",
    "            'Shock_Amplify_3w': shock_amplify_3w.iloc[i],\n",
    "            'Shock_Delta': shock_delta.iloc[i],\n",
    "            'Vol_Flag': vol_flag.iloc[i],\n",
    "            'KD_Signal': kd_signal.iloc[i],\n",
    "            'MACD': macd.iloc[i],\n",
    "            'MACD_Slope': macd_slope.iloc[i],\n",
    "            'ROC_5w': close.pct_change(5).iloc[i],\n",
    "            'Momentum_2w': momentum_2w.iloc[i],\n",
    "            'KD_Signal_x_Shock3w': kd_x_shock.iloc[i],\n",
    "            'Streak_x_Return6w': streak_x_ret6.iloc[i],\n",
    "            'Target_Next_Week_Return': close.pct_change(1).shift(-1).iloc[i],\n",
    "            'Direction': (close.pct_change(1).shift(-1).iloc[i] > 0).astype(int),\n",
    "        }\n",
    "\n",
    "        feature_rows.append(row)\n",
    "\n",
    "# === Assemble + Clip Outliers ===\n",
    "feature_df = pd.DataFrame(feature_rows)\n",
    "feature_df.dropna(inplace=True)\n",
    "\n",
    "# Clip each feature to 1st‚Äì99th percentile\n",
    "for col in feature_df.columns:\n",
    "    if col not in ['Date', 'ETF', 'Direction']:\n",
    "        lower = feature_df[col].quantile(0.01)\n",
    "        upper = feature_df[col].quantile(0.99)\n",
    "        feature_df[col] = feature_df[col].clip(lower, upper)\n",
    "\n",
    "# Optional: Flag outlier conditions\n",
    "values = feature_df.drop(columns=['Date', 'ETF', 'Direction'])\n",
    "z_scores = (values - values.mean()) / values.std()\n",
    "del values\n",
    "feature_df['Edge_Flag'] = (np.abs(z_scores) > 2.5).sum(axis=1) > 3\n",
    "\n",
    "# Save\n",
    "feature_df.to_csv('../dataset/etf_features.csv', index=False)\n",
    "print(\"‚úÖ Feature CSV with outlier clipping and edge flag saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3f2fb",
   "metadata": {},
   "source": [
    "### üìå Deep Sector Rotation Strategy with Shock-Aware Early Exit\n",
    "\n",
    "This strategy builds on the \"Deep Sector Rotation\" approach proposed in [SSRN-4280640](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4280640), with the following modifications:\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Core Model (MLP)\n",
    "\n",
    "- A multi-layer perceptron (MLP) is trained to predict next-week returns for each ETF independently.\n",
    "- Features include:\n",
    "  - Past 1w, 3w, 6w returns\n",
    "  - Volume (log normalized)\n",
    "  - Macro indicators (VIX, 10Y yield, USD index, oil)\n",
    "  - Streak up count (3-week up trend)\n",
    "  - Shock Amplify features:\n",
    "    - This week\n",
    "    - 1-week lag\n",
    "    - 3-week average\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Weekly Rotation Rule (baseline)\n",
    "\n",
    "- Each week (e.g., Monday), predict returns for all ETFs using the MLP.\n",
    "- Rank the ETFs by predicted return.\n",
    "- Buy top-N (e.g., 3) ETFs.\n",
    "- Hold for 1 week (unless overridden by shock rule below).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö° Shock Amplify Early Exit Rule (custom addition)\n",
    "\n",
    "- Each day (or evaluation step), check for ETFs in the portfolio with:\n",
    "  - `Shock_Amplify_3w` > +10% or < -10%\n",
    "- If triggered:\n",
    "  - Sell that ETF immediately.\n",
    "  - Immediately start a new turn (predict again, re-select top-N).\n",
    "\n",
    "---\n",
    "\n",
    "#### üíº Goal\n",
    "\n",
    "- Combine deep learning-based prediction with handcrafted rules for volatility control.\n",
    "- Achieve more stable and responsive ETF swing trading performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d156386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Ë≥áÊñôÊ∫ñÂÇô (ÂÅáË®≠‰Ω†Â∑≤Á∂ìÊúâ DataFrame Ê†ºÂºèÁöÑ ETF Ë≥áÊñôÂíå Macro ÊåáÊ®ôË≥áÊñô)\n",
    "\n",
    "TEST_PERCENTAGE = 0.2\n",
    "\n",
    "# ÁØÑ‰æã ETF Ë≥áÊñô (DataFrame) - ÂÅáË®≠‰Ω†ÁöÑ ETF Ë≥áÊñôÊòØ DataFrame Ê†ºÂºèÔºåÊØèË°å‰ª£Ë°®‰∏ÄÂ§©‰∏ÄÂÄã ETF ÁöÑË≥áÊñô\n",
    "# ÂØ¶ÈöõÊÉÖÊ≥Å‰Ω†ÈúÄË¶ÅÂæû‰Ω†ÁöÑË≥áÊñô‰æÜÊ∫êËºâÂÖ•\n",
    "etf_data = pd.read_csv('../dataset/etf_features.csv')\n",
    "\n",
    "# ÁØÑ‰æã Macro ÊåáÊ®ôË≥áÊñô (DataFrame) - ÂÅáË®≠‰Ω†ÁöÑ Macro ÊåáÊ®ôË≥áÊñôÊòØ DataFrame Ê†ºÂºèÔºåÊØèË°å‰ª£Ë°®‰∏ÄÂ§©ÁöÑ Macro ÊåáÊ®ô\n",
    "# ÂØ¶ÈöõÊÉÖÊ≥Å‰Ω†ÈúÄË¶ÅÂæû‰Ω†ÁöÑË≥áÊñô‰æÜÊ∫êËºâÂÖ•\n",
    "macro_data = pd.read_csv('../dataset/macro_indicators_weekly.csv', index_col=0)\n",
    "\n",
    "# ÂÆöÁæ©Ë¶Å‰ΩøÁî®ÁöÑ ETF ÁâπÂæµÂàó (ÊéíÈô§ Date, ETF, Target, Direction Á≠âÈùûÁâπÂæµÂàó)\n",
    "etf_feature_cols = [\n",
    "    'Return_1w', 'Return_3w', 'Return_6w', 'Streak_Up', 'LogVolumeNorm',\n",
    "    'Shock_Amplify', 'Shock_Amplify_1w', 'Shock_Amplify_3w', 'Shock_Delta',\n",
    "    'Vol_Flag', 'KD_Signal', 'MACD', 'MACD_Slope', 'ROC_5w', 'Momentum_2w',\n",
    "    'KD_Signal_x_Shock3w', 'Streak_x_Return6w'\n",
    "]\n",
    "\n",
    "# ÂÆöÁæ©Ë¶Å‰ΩøÁî®ÁöÑ Macro ÊåáÊ®ôÂàó\n",
    "macro_feature_cols = ['VIX', '10Y_Yield', 'USD_Index', 'WTI_Crude']\n",
    "\n",
    "# 2. Ë≥áÊñôÈõÜ (Dataset) ÂÆöÁæ©\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, etf_df, macro_df, etf_feature_cols, macro_feature_cols, test_percentage=0.2, etf_list=None):\n",
    "        self.etf_df = etf_df\n",
    "        self.macro_df = macro_df\n",
    "        self.etf_feature_cols = etf_feature_cols\n",
    "        self.macro_feature_cols = macro_feature_cols\n",
    "        if etf_list is None:\n",
    "            self.etf_list = sorted(list(etf_df['ETF'].unique())) # ÂèñÂæó ETF Ê∏ÖÂñÆ\n",
    "        else:\n",
    "            self.etf_list = etf_list\n",
    "\n",
    "        # Ë≥áÊñôÈ†êËôïÁêÜÂíåÁâπÂæµÂ∑•Á®ã\n",
    "        self.processed_data = self._preprocess_data()\n",
    "        self.test_len = int(len(self.processed_data) * test_percentage)\n",
    "        self.train_len = len(self.processed_data) - self.test_len\n",
    "        self.train_test_flag = 0 # 0 for train, 1 for test\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        processed_list = [] # processed_list ÁèæÂú®ÊòØÊ®£Êú¨ÂàóË°®\n",
    "\n",
    "        for etf_symbol in self.etf_list:\n",
    "            etf_subset = self.etf_df[self.etf_df['ETF'] == etf_symbol].sort_values(by='Date')\n",
    "            if etf_subset.empty:\n",
    "                continue\n",
    "\n",
    "            dates_full = etf_subset['Date'].values\n",
    "            etf_features_full = etf_subset[self.etf_feature_cols].values\n",
    "            targets_full = etf_subset['Target_Next_Week_Return'].values.reshape(-1, 1)\n",
    "            macro_features_full = self.macro_df.loc[dates_full][self.macro_feature_cols].values\n",
    "\n",
    "            seq_len = 12 # Ë®≠ÂÆöÂ∫èÂàóÈï∑Â∫¶ (‰æãÂ¶Ç 12 Âë®) - ‰Ω†ÂèØ‰ª•Ê†πÊìöÈúÄË¶ÅË™øÊï¥\n",
    "            interval = 4 \n",
    "            for i in range(seq_len, len(etf_features_full), interval): # ÊªëÂãïÁ™óÂè£ÁîüÊàêÊ®£Êú¨\n",
    "                start_index = i - seq_len\n",
    "                end_index = i\n",
    "\n",
    "                etf_features = etf_features_full[start_index:end_index] # ÂèñÈÅéÂéª seq_len Â§©ÁöÑ ETF ÁâπÂæµ\n",
    "                target = targets_full[end_index] # ÂèñÁï∂Â§© (end_index) ÁöÑÁõÆÊ®ôÂÄº\n",
    "                dates = \",\".join(dates_full[start_index:end_index]) # ÂèñÈÅéÂéª seq_len Â§©ÁöÑÊó•Êúü\n",
    "                macro_features = macro_features_full[start_index:end_index] # ÂèñÈÅéÂéª seq_len Â§©ÁöÑ Macro ÁâπÂæµ\n",
    "\n",
    "                # Ê®ôÊ∫ñÂåñ (ÂèØ‰ª•ËÄÉÊÖÆÂú®ÊâπÊ¨°‰∏≠Ê®ôÊ∫ñÂåñÔºåËÄå‰∏çÊòØÂú®Ê®£Êú¨‰∏≠Ê®ôÊ∫ñÂåñ)\n",
    "                # etf_features = StandardScaler().fit_transform(etf_features)\n",
    "                # macro_features = StandardScaler().fit_transform(macro_features)\n",
    "\n",
    "                processed_list.append({ # ÁîüÊàêÂñÆÂÄãÊ®£Êú¨\n",
    "                    'etf_features': torch.tensor(etf_features, dtype=torch.float32),\n",
    "                    'macro_features': torch.tensor(macro_features, dtype=torch.float32),\n",
    "                    'targets': torch.tensor(target, dtype=torch.float32), # ÁõÆÊ®ôÂÄºÁèæÂú®ÊòØÂñÆÂÄãÊï∏ÂÄº\n",
    "                    'dates': dates,\n",
    "                    'etf_symbol': etf_symbol\n",
    "                })\n",
    "        return processed_list # ËøîÂõûÊ®£Êú¨ÂàóË°®\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_test_flag = 0\n",
    "\n",
    "    def test(self):\n",
    "        self.train_test_flag = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train_len if self.train_test_flag == 0 else self.test_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx] if self.train_test_flag == 0 else self.processed_data[self.train_len + idx]\n",
    "\n",
    "# 4. Ê®°ÂûãË®ìÁ∑¥ (Á∞°ÂåñÁØÑ‰æã)\n",
    "\n",
    "# Ë∂ÖÂèÉÊï∏Ë®≠ÂÆö\n",
    "ETF_FEATURE_DIM = len(etf_feature_cols)\n",
    "MACRO_FEATURE_DIM = len(macro_feature_cols)\n",
    "TRANSFORMER_DIM = 128\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 32\n",
    "OUTPUT_DIM = 1 # È†êÊ∏¨‰∏ãÈÄ±Êº≤Ë∑åÂπÖÂ∫¶ (ÂñÆ‰∏ÄÊï∏ÂÄº)\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Âª∫Á´ãË≥áÊñôÈõÜÂíåË≥áÊñôËºâÂÖ•Âô®\n",
    "dataset = StockDataset(etf_data, macro_data, etf_feature_cols, macro_feature_cols, test_percentage=TEST_PERCENTAGE)\n",
    "dataset.train()\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True) # batch_size Ë®≠ÁÇ∫ 1ÔºåÊñπ‰æøÁØÑ‰æãÁêÜËß£\n",
    "\n",
    "# 5. Ê®°ÂûãË©ï‰º∞ (Á∞°ÂåñÁØÑ‰æã) - ‰Ω†ÈúÄË¶ÅÊ∫ñÂÇôÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰∏¶Ë©ï‰º∞Ê®°ÂûãÊÄßËÉΩ\n",
    "# ... (Ê®°ÂûãË©ï‰º∞Á®ãÂºèÁ¢ºÔºå‰æãÂ¶ÇË®àÁÆó RMSE, MAE Á≠âÊåáÊ®ô)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbd4a227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Average Loss: 0.0609\n",
      "Epoch [2/20], Average Loss: 0.0013\n",
      "Epoch [3/20], Average Loss: 0.0012\n",
      "Epoch [4/20], Average Loss: 0.0011\n",
      "Epoch [5/20], Average Loss: 0.0010\n",
      "Epoch [6/20], Average Loss: 0.0011\n",
      "Epoch [7/20], Average Loss: 0.0010\n",
      "Epoch [8/20], Average Loss: 0.0010\n",
      "Epoch [9/20], Average Loss: 0.0010\n",
      "Epoch [10/20], Average Loss: 0.0009\n",
      "Epoch [11/20], Average Loss: 0.0009\n",
      "Epoch [12/20], Average Loss: 0.0009\n",
      "Epoch [13/20], Average Loss: 0.0009\n",
      "Epoch [14/20], Average Loss: 0.0009\n",
      "Epoch [15/20], Average Loss: 0.0008\n",
      "Epoch [16/20], Average Loss: 0.0008\n",
      "Epoch [17/20], Average Loss: 0.0009\n",
      "Epoch [18/20], Average Loss: 0.0008\n",
      "Epoch [19/20], Average Loss: 0.0008\n",
      "Epoch [20/20], Average Loss: 0.0008\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# 3. Ê®°ÂûãÂÆöÁæ© (Transformer Ê®°Âûã)\n",
    "\n",
    "class StockPredictionTransformer(nn.Module):\n",
    "    def __init__(self, etf_feature_dim, macro_feature_dim, input_dim, num_heads, num_layers, batch_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        # Ëº∏ÂÖ•ÂµåÂÖ•Â±§ (Input Embedding)\n",
    "        self.etf_embedding = nn.Linear(etf_feature_dim, input_dim)\n",
    "        self.macro_embedding = nn.Linear(macro_feature_dim, input_dim)\n",
    "        self.etf_norm = nn.BatchNorm1d(input_dim)\n",
    "        self.macro_norm = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        # Transformer Encoder Â±§\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=2 * input_dim, nhead=num_heads) # *2 for etf and macro output dim\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # ËûçÂêàÂ±§ (Á∞°ÂñÆÊãºÊé•ÂæåÁöÑÂÖ®ÈÄ£Êé•Â±§)\n",
    "        self.fusion_layer = nn.Linear(2 * input_dim, input_dim) # ÊãºÊé• ETF Âíå Macro ÁâπÂæµ\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Ëº∏Âá∫Â±§ (ÂõûÊ≠∏È†êÊ∏¨‰∏ãÈÄ±Êº≤Ë∑åÂπÖÂ∫¶)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, etf_features, macro_features):\n",
    "        # Ëº∏ÂÖ•ÂµåÂÖ•\n",
    "        etf_embedded = self.relu(self.etf_embedding(etf_features)) # [batch_size, seq_len, transformer_dim] - ÂÅáË®≠‰øÆÊ≠£ÂæåÂΩ¢ÁãÄÁÇ∫ 3 Á∂≠\n",
    "        macro_embedded = self.relu(self.macro_embedding(macro_features)) # [batch_size, seq_len, transformer_dim] - ÂÅáË®≠‰øÆÊ≠£ÂæåÂΩ¢ÁãÄÁÇ∫ 3 Á∂≠\n",
    "\n",
    "        # Batch normalize (ÈúÄË¶ÅË™øÊï¥Ëº∏ÂÖ•ÂΩ¢ÁãÄÁÇ∫ [batch_size, feature_dim, seq_len])\n",
    "        etf_embedded = etf_embedded.transpose(1, 2)\n",
    "        macro_embedded = macro_embedded.transpose(1, 2)\n",
    "\n",
    "        etf_normed = self.etf_norm(etf_embedded)\n",
    "        macro_normed = self.macro_norm(macro_embedded)\n",
    "\n",
    "        # Transformer Encoder (ÈúÄË¶ÅË™øÊï¥Ëº∏ÂÖ•ÂΩ¢ÁãÄÁÇ∫ (seq_len, batch_size, feature_dim))\n",
    "        # ÈÄôË£°ÂÅáË®≠ batch_first=FalseÔºåÊâÄ‰ª•ÈúÄË¶ÅÂ∞á batch_size Á∂≠Â∫¶ÊîæÂà∞Á¨¨‰∫åÁ∂≠\n",
    "        etf_normed = etf_normed.permute(2, 0, 1) # [seq_len, batch_size, transformer_dim]\n",
    "        macro_normed = macro_normed.permute(2, 0, 1) # [seq_len, batch_size, transformer_dim]\n",
    "\n",
    "        # ÊãºÊé• ETF Âíå Macro ÁâπÂæµ (Âú® feature Á∂≠Â∫¶ÊãºÊé•, dim=2)\n",
    "        fused_features = torch.cat((etf_normed, macro_normed), dim=2) # [seq_len, batch_size, 2*transformer_dim]\n",
    "\n",
    "        # ÈÄèÈÅé Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(fused_features) # [seq_len, batch_size, transformer_dim]\n",
    "\n",
    "        # Âèñ Transformer Ëº∏Âá∫ÁöÑÊúÄÂæå‰∏ÄÂÄãÊôÇÈñìÊ≠•ÁöÑÁâπÂæµ (ÂèØ‰ª•Áî®Âπ≥ÂùáÊ±†ÂåñÊàñÂÖ∂‰ªñÊñπÂºè)\n",
    "        output_feature = transformer_output[-1, :, :] # [batch_size, transformer_dim]\n",
    "\n",
    "        # ËûçÂêàÂ±§\n",
    "        fused_output = self.relu(self.fusion_layer(output_feature)) # [batch_size, transformer_dim]\n",
    "\n",
    "        # Ëº∏Âá∫Â±§\n",
    "        prediction = self.output_layer(fused_output) # [batch_size, output_dim]\n",
    "\n",
    "        return prediction.squeeze(1) # [output_dim]\n",
    "\n",
    "# Âª∫Á´ãÊ®°Âûã„ÄÅÊêçÂ§±ÂáΩÊï∏ÂíåÂÑ™ÂåñÂô®\n",
    "model = StockPredictionTransformer(ETF_FEATURE_DIM, MACRO_FEATURE_DIM, TRANSFORMER_DIM, NUM_HEADS, NUM_LAYERS, BATCH_SIZE, OUTPUT_DIM)\n",
    "criterion = nn.MSELoss() # ÂùáÊñπË™§Â∑ÆÊêçÂ§±ÂáΩÊï∏ (ÂõûÊ≠∏‰ªªÂãô)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Ë®ìÁ∑¥Ëø¥Âúà (Á∞°ÂåñÁØÑ‰æã)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train() # Ë®≠ÂÆöÊ®°ÂûãÁÇ∫Ë®ìÁ∑¥Ê®°Âºè\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        etf_features = batch['etf_features'] # [seq_len, feature_dim]\n",
    "        macro_features = batch['macro_features'] # [seq_len, feature_dim]\n",
    "        targets = batch['targets'] # [seq_len, 1]\n",
    "\n",
    "        # ÂâçÂêëÂÇ≥Êí≠\n",
    "        outputs = model(etf_features, macro_features) # [output_dim]\n",
    "\n",
    "        # Ë®àÁÆóÊêçÂ§± (Âè™ÂèñÊúÄÂæå‰∏ÄÂÄãÊôÇÈñìÊ≠•ÁöÑÁõÆÊ®ôÂÄºÈÄ≤Ë°åÊØîËºÉÔºåÁØÑ‰æãÁ∞°ÂåñËôïÁêÜ)\n",
    "        loss = criterion(outputs, targets.squeeze()) # targets[-1] ÂèñÊúÄÂæå‰∏ÄÂÄãÊôÇÈñìÊ≠•ÁöÑÁõÆÊ®ôÂÄºÔºå‰∏¶ÁßªÈô§ batch_size Á∂≠Â∫¶\n",
    "\n",
    "        # ÂèçÂêëÂÇ≥Êí≠ÂíåÂÑ™Âåñ\n",
    "        optimizer.zero_grad() # Ê∏ÖÁ©∫Ê¢ØÂ∫¶\n",
    "        loss.backward() # ÂèçÂêëÂÇ≥Êí≠Ë®àÁÆóÊ¢ØÂ∫¶\n",
    "        optimizer.step() # Êõ¥Êñ∞Ê®°ÂûãÂèÉÊï∏\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0d6be12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['XLRE', 'XLU', 'XLV', 'XLY'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# (ÂÅáË®≠‰Ω†Â∑≤Á∂ìÂÆöÁæ©‰∫Ü StockDataset Âíå StockPredictionTransformer Ê®°Âûã)\n",
    "# (ÂÅáË®≠‰Ω†Â∑≤Á∂ìË®ìÁ∑¥Â•Ω‰∫ÜÊ®°Âûã model)\n",
    "# (ÂÅáË®≠‰Ω†Â∑≤Á∂ìÊ∫ñÂÇôÂ•Ω‰∫ÜÊ∏¨Ë©¶Áî®ÁöÑ test_etf_data Âíå test_macro_data)\n",
    "\n",
    "# Ë®≠ÂÆöÊ®°ÂûãÁÇ∫Ë©ï‰º∞Ê®°Âºè\n",
    "model.eval()\n",
    "\n",
    "# Ê∫ñÂÇôÊ∏¨Ë©¶Ë≥áÊñôÈõÜÂíåË≥áÊñôËºâÂÖ•Âô®\n",
    "dataset.test() # ‰ΩøÁî®ËàáË®ìÁ∑¥ÈõÜÁõ∏ÂêåÁöÑ ETF ÂàóË°®\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False) # batch_size ÂèØ‰ª•ËàáË®ìÁ∑¥ÊôÇÁõ∏ÂêåÔºåshuffle=False\n",
    "\n",
    "predictions = {} # ÂÑ≤Â≠òÊâÄÊúâÈ†êÊ∏¨ÁµêÊûú\n",
    "actual_targets = {} # ÂÑ≤Â≠òÊâÄÊúâÁúüÂØ¶ÁõÆÊ®ôÂÄº\n",
    "date_of_inputs = {}\n",
    "\n",
    "with torch.no_grad(): # ÈóúÈñâÊ¢ØÂ∫¶Ë®àÁÆó\n",
    "    for batch in test_dataloader:\n",
    "        etf_features = batch['etf_features']\n",
    "        macro_features = batch['macro_features']\n",
    "        targets = batch['targets']\n",
    "        dates = batch['dates']\n",
    "        etf_symbol = batch['etf_symbol']\n",
    "\n",
    "        # ÂâçÂêëÂÇ≥Êí≠ÔºåÁç≤ÂèñÈ†êÊ∏¨Ëº∏Âá∫\n",
    "        outputs = model(etf_features, macro_features)\n",
    "\n",
    "        # Â∞áÈ†êÊ∏¨ÁµêÊûúÂíåÁúüÂØ¶ÁõÆÊ®ôÂÄºËΩâÊèõÁÇ∫ NumPy array ‰∏¶ÂÑ≤Â≠ò\n",
    "        for etf, d, pred, real in zip(etf_symbol, dates, outputs.cpu().numpy(), targets.cpu().numpy()):\n",
    "            predictions.setdefault(etf, []).append(pred)\n",
    "            actual_targets.setdefault(etf, []).append(real)\n",
    "            date_of_inputs.setdefault(etf, []).append(d.split(',')[-1])\n",
    "\n",
    "# # Â∞áÈ†êÊ∏¨ÁµêÊûúÂíåÁúüÂØ¶ÁõÆÊ®ôÂÄºÂàóË°®ËΩâÊèõÁÇ∫ NumPy array\n",
    "for etf in predictions:\n",
    "    predictions[etf] = np.array(predictions[etf])\n",
    "    actual_targets[etf] = np.array(actual_targets[etf]).flatten()\n",
    "    date_of_inputs[etf] = np.array(date_of_inputs[etf])\n",
    "\n",
    "# # Ë®àÁÆóË©ï‰º∞ÊåáÊ®ô\n",
    "# rmse = np.sqrt(mean_squared_error(actual_targets, predictions))\n",
    "# mae = mean_absolute_error(actual_targets, predictions)\n",
    "# r2 = r2_score(actual_targets, predictions)\n",
    "\n",
    "# print(\"Evaluation Results:\")\n",
    "# print(f\"RMSE: {rmse:.4f}\")\n",
    "# print(f\"MAE: {mae:.4f}\")\n",
    "# print(f\"R-squared: {r2:.4f}\")\n",
    "predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a9759f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Predictions",
         "type": "scatter",
         "x": [
          "2021-08-23",
          "2021-09-20",
          "2021-10-18",
          "2021-11-15",
          "2021-12-13",
          "2022-01-10",
          "2022-02-07",
          "2022-03-07",
          "2022-04-04",
          "2022-05-02",
          "2022-05-30",
          "2022-06-27",
          "2022-07-25",
          "2022-08-22",
          "2022-09-19",
          "2022-10-17",
          "2022-11-14",
          "2022-12-12",
          "2023-01-09",
          "2023-02-06",
          "2023-03-06",
          "2023-04-03",
          "2023-05-01",
          "2023-05-29",
          "2023-06-26",
          "2023-07-24",
          "2023-08-21",
          "2023-09-18",
          "2023-10-16",
          "2023-11-13",
          "2023-12-11",
          "2024-01-08",
          "2024-02-05",
          "2024-03-04",
          "2024-04-01",
          "2024-04-29",
          "2024-05-27",
          "2024-06-24",
          "2024-07-22",
          "2024-08-19",
          "2024-09-16",
          "2024-10-14",
          "2024-11-11",
          "2024-12-09",
          "2025-01-06",
          "2025-02-03",
          "2025-03-03",
          "2025-03-31"
         ],
         "xaxis": "x",
         "y": [
          -0.0020613856613636017,
          0.004083478823304176,
          0.000017840415239334106,
          0.002794945612549782,
          0.004461443051695824,
          0.004140971228480339,
          0.009060617536306381,
          0.006907694041728973,
          0.0023986361920833588,
          0.005301821976900101,
          -0.0005900450050830841,
          0.003385661169886589,
          0.010098934173583984,
          0.012989815324544907,
          0.011296678334474564,
          0.006692182272672653,
          0.005425620824098587,
          0.005034828558564186,
          0.0031747985631227493,
          0.001942649483680725,
          0.010234754532575607,
          0.0012828931212425232,
          0.0017507560551166534,
          0.0017424337565898895,
          0.0023611020296812057,
          -0.00081678107380867,
          -0.00028516724705696106,
          0.007109209895133972,
          0.00928979367017746,
          0.0046744439750909805,
          0.004274200648069382,
          0.0014611296355724335,
          -0.000506846234202385,
          0.0009648259729146957,
          0.0038264989852905273,
          0.002642538398504257,
          0.002330036833882332,
          0.0024737026542425156,
          0.004973776638507843,
          0.002595040947198868,
          0.005569750443100929,
          0.006539687514305115,
          0.006302155554294586,
          0.0026151128113269806,
          0.002989809960126877,
          0.0018957220017910004,
          0.004096096381545067,
          0.00520954467356205
         ],
         "yaxis": "y"
        },
        {
         "name": "Real",
         "type": "scatter",
         "x": [
          "2021-08-23",
          "2021-09-20",
          "2021-10-18",
          "2021-11-15",
          "2021-12-13",
          "2022-01-10",
          "2022-02-07",
          "2022-03-07",
          "2022-04-04",
          "2022-05-02",
          "2022-05-30",
          "2022-06-27",
          "2022-07-25",
          "2022-08-22",
          "2022-09-19",
          "2022-10-17",
          "2022-11-14",
          "2022-12-12",
          "2023-01-09",
          "2023-02-06",
          "2023-03-06",
          "2023-04-03",
          "2023-05-01",
          "2023-05-29",
          "2023-06-26",
          "2023-07-24",
          "2023-08-21",
          "2023-09-18",
          "2023-10-16",
          "2023-11-13",
          "2023-12-11",
          "2024-01-08",
          "2024-02-05",
          "2024-03-04",
          "2024-04-01",
          "2024-04-29",
          "2024-05-27",
          "2024-06-24",
          "2024-07-22",
          "2024-08-19",
          "2024-09-16",
          "2024-10-14",
          "2024-11-11",
          "2024-12-09",
          "2025-01-06",
          "2025-02-03",
          "2025-03-03",
          "2025-03-31"
         ],
         "xaxis": "x",
         "y": [
          -0.03857995197176933,
          -0.006899747531861067,
          0.008364520967006683,
          0.00020921175018884242,
          0.04674933850765228,
          -0.0014928526943549514,
          0.02640995942056179,
          -0.0021173327695578337,
          0.012510256841778755,
          -0.01717326045036316,
          -0.05076512321829796,
          -0.005578336771577597,
          0.04162862151861191,
          0.04263562336564064,
          -0.041099872440099716,
          -0.017110275104641914,
          0.0043816897086799145,
          0.007262854836881161,
          0.028811637312173843,
          -0.037364326417446136,
          -0.019873103126883507,
          0.015847057104110718,
          -0.023726318031549454,
          0.015355614945292473,
          0.026462135836482048,
          0.008632401004433632,
          -0.010270089842379093,
          -0.01496924739331007,
          0.08140150457620621,
          0.0465310662984848,
          0.0190314631909132,
          -0.005426337476819754,
          0.009648174047470093,
          -0.01075846329331398,
          -0.036519721150398254,
          0.025125635787844658,
          0.01474846713244915,
          0.0441252700984478,
          -0.0011944037396460772,
          0.0018369758035987616,
          -0.010497935116291046,
          -0.030179163441061974,
          0.020639613270759583,
          -0.006129015702754259,
          0.011440987698733807,
          0.004041748587042093,
          0.0014474708586931229,
          0.039311476051807404
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "XLRE"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "etf = 'XLRE'\n",
    "sorted_idx = date_of_inputs[etf].argsort()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x = date_of_inputs[etf][sorted_idx], y = predictions[etf][sorted_idx], name='Predictions'), 1, 1)\n",
    "fig.add_trace(go.Scatter(x = date_of_inputs[etf][sorted_idx], y = actual_targets[etf][sorted_idx], name='Real'), 1, 1)\n",
    "fig.update_layout(title=f'{etf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f9824",
   "metadata": {},
   "source": [
    "#### Tensorflow ver. (not tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tf_keras as keras\n",
    "from tf_keras import layers\n",
    "\n",
    "# 1. Ê®°Êì¨Ëº∏ÂÖ•Êï∏Êìö (‰ΩøÁî®Èö®Ê©üÊï∏ÊìöÔºåÂØ¶ÈöõÊáâÁî®‰∏≠ÈúÄË¶ÅËÆÄÂèñÁúüÂØ¶Êï∏Êìö)\n",
    "def generate_dummy_data(num_samples, num_etfs, num_news_features):\n",
    "    dates = pd.date_range('2023-01-01', periods=num_samples, freq='D')\n",
    "    etf_symbols = [f'ETF_{i}' for i in range(num_etfs)]\n",
    "    macro_feature_names = list(macro_tickers.keys())\n",
    "    etf_data_list = []\n",
    "    macro_data_df = pd.DataFrame(index=dates)\n",
    "    news_data_df = pd.DataFrame(index=dates)\n",
    "\n",
    "    for symbol in etf_symbols:\n",
    "        etf_df = pd.DataFrame({\n",
    "            'Date': dates,\n",
    "            'ETF': symbol,\n",
    "            'Return_1w': np.random.randn(num_samples),\n",
    "            'Return_3w': np.random.randn(num_samples),\n",
    "            'Return_6w': np.random.randn(num_samples),\n",
    "            'Streak_Up': np.random.randint(0, 10, num_samples),\n",
    "            'LogVolumeNorm': np.random.randn(num_samples),\n",
    "            'Shock_Amplify': np.random.randn(num_samples),\n",
    "            'Shock_Amplify_1w': np.random.randn(num_samples),\n",
    "            'Shock_Amplify_3w': np.random.randn(num_samples),\n",
    "            'Shock_Delta': np.random.randn(num_samples),\n",
    "            'Vol_Flag': np.random.randint(0, 2, num_samples),\n",
    "            'KD_Signal': np.random.randn(num_samples),\n",
    "            'MACD': np.random.randn(num_samples),\n",
    "            'MACD_Slope': np.random.randn(num_samples),\n",
    "            'ROC_5w': np.random.randn(num_samples),\n",
    "            'Momentum_2w': np.random.randn(num_samples),\n",
    "            'KD_Signal_x_Shock3w': np.random.randn(num_samples),\n",
    "            'Streak_x_Return6w': np.random.randn(num_samples),\n",
    "            'Target_Next_Week_Return': np.random.randn(num_samples), # Ê®°Êì¨ÁõÆÊ®ôÂÄº\n",
    "            'Direction': np.random.randint(0, 2, num_samples), # Ê®°Êì¨ÊñπÂêë (ÂàÜÈ°û‰ªªÂãôÂèØÈÅ∏)\n",
    "        })\n",
    "        etf_data_list.append(etf_df)\n",
    "    etf_data = pd.concat(etf_data_list)\n",
    "\n",
    "    for feature_name in macro_feature_names:\n",
    "        macro_data_df[feature_name] = np.random.randn(num_samples)\n",
    "\n",
    "    for i in range(num_news_features):\n",
    "        news_data_df[f'News_Impact_{i}'] = np.random.randn(num_samples)\n",
    "\n",
    "    return etf_data, macro_data_df, news_data_df\n",
    "\n",
    "# 2. Ë≥áÊñôÈ†êËôïÁêÜÂáΩÊï∏\n",
    "def preprocess_etf_data(etf_df):\n",
    "    etf_df_processed = etf_df.copy()\n",
    "    # Áº∫Â§±ÂÄºËôïÁêÜ (Á∞°ÂñÆÁ§∫‰æãÔºö‰ΩøÁî®ÂùáÂÄºÂ°´Ë£ú)\n",
    "    etf_df_processed = etf_df_processed.fillna(etf_df_processed.mean(numeric_only=True))\n",
    "    # Êï∏ÂÄºÁâπÂæµÂàóË°® (ÊéíÈô§ Date, ETF, Target, Direction Á≠âÈùûÊï∏ÂÄºÊàñÁõÆÊ®ôÊ¨Ñ‰Ωç)\n",
    "    numerical_features = [col for col in etf_df_processed.columns if col not in ['Date', 'ETF', 'Target_Next_Week_Return', 'Direction']]\n",
    "    # Ê®ôÊ∫ñÂåñ/Ê≠∏‰∏ÄÂåñ (MinMaxScaler)\n",
    "    scaler = MinMaxScaler()\n",
    "    etf_df_processed[numerical_features] = scaler.fit_transform(etf_df_processed[numerical_features])\n",
    "    return etf_df_processed, scaler # ËøîÂõû scaler ‰ª•‰æøÂæåÁ∫å‰ΩøÁî®\n",
    "\n",
    "def preprocess_macro_data(macro_df):\n",
    "    macro_df_processed = macro_df.copy()\n",
    "    # Áº∫Â§±ÂÄºËôïÁêÜ (Á∞°ÂñÆÁ§∫‰æãÔºö‰ΩøÁî®ÂùáÂÄºÂ°´Ë£ú)\n",
    "    macro_df_processed = macro_df_processed.fillna(macro_df_processed.mean(numeric_only=True))\n",
    "    # Ê®ôÊ∫ñÂåñ/Ê≠∏‰∏ÄÂåñ (MinMaxScaler)\n",
    "    scaler = MinMaxScaler()\n",
    "    macro_df_processed = scaler.fit_transform(macro_df_processed)\n",
    "    return macro_df_processed, scaler\n",
    "\n",
    "def preprocess_news_data(news_df):\n",
    "    news_df_processed = news_df.copy()\n",
    "    # Áº∫Â§±ÂÄºËôïÁêÜ (Á∞°ÂñÆÁ§∫‰æãÔºö‰ΩøÁî®ÂùáÂÄºÂ°´Ë£ú)\n",
    "    news_df_processed = news_df_processed.fillna(news_df_processed.mean(numeric_only=True))\n",
    "    # Ê®ôÊ∫ñÂåñ/Ê≠∏‰∏ÄÂåñ (MinMaxScaler)\n",
    "    scaler = MinMaxScaler()\n",
    "    news_df_processed = scaler.fit_transform(news_df_processed)\n",
    "    return news_df_processed, scaler\n",
    "\n",
    "# 3. ÂâµÂª∫ Transformer Encoder Ê®°Âûã\n",
    "def create_transformer_encoder_model(input_shape_etf, input_shape_macro, input_shape_news, num_transformer_layers=2, num_heads=4, ff_dim=32, output_dim=1):\n",
    "    # ETF Ëº∏ÂÖ•ÂàÜÊîØ\n",
    "    input_etf = layers.Input(shape=input_shape_etf, name=\"etf_input\")\n",
    "    embedding_etf = layers.Dense(ff_dim)(input_etf) # Á∞°ÂñÆÁ∑öÊÄßÂµåÂÖ•\n",
    "    positional_encoding_etf = layers.LayerNormalization(epsilon=1e-6)(embedding_etf) # Á∞°ÂñÆ‰ΩçÁΩÆÁ∑®Á¢º - Ê≠§ËôïÁ∞°ÂåñÔºåÂØ¶ÈöõÂèØ‰ΩøÁî®Êõ¥Ë§áÈõúÁöÑ‰ΩçÁΩÆÁ∑®Á¢º\n",
    "\n",
    "    x_etf = positional_encoding_etf\n",
    "    for _ in range(num_transformer_layers):\n",
    "        attention_output_etf = layers.MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x_etf, x_etf)\n",
    "        attention_output_etf = layers.Dropout(0.1)(attention_output_etf)\n",
    "        out1_etf = layers.Add()([x_etf, attention_output_etf])\n",
    "        out1_etf = layers.LayerNormalization(epsilon=1e-6)(out1_etf)\n",
    "\n",
    "        ffn_etf = layers.Dense(ff_dim, activation=\"relu\")(out1_etf)\n",
    "        ffn_output_etf = layers.Dense(ff_dim)(ffn_etf)\n",
    "        ffn_output_etf = layers.Dropout(0.1)(ffn_output_etf)\n",
    "        x_etf = layers.Add()([out1_etf, ffn_output_etf])\n",
    "        x_etf = layers.LayerNormalization(epsilon=1e-6)(x_etf)\n",
    "\n",
    "    transformer_output_etf = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x_etf) if x_etf.shape[1] is not None else layers.Flatten()(x_etf) # ËôïÁêÜÊôÇÈñìÂ∫èÂàóÊàñÊâÅÂπ≥Ëº∏ÂÖ•\n",
    "\n",
    "    # Macro ÊåáÊ®ôËº∏ÂÖ•ÂàÜÊîØ\n",
    "    input_macro = layers.Input(shape=input_shape_macro, name=\"macro_input\")\n",
    "    embedding_macro = layers.Dense(ff_dim)(input_macro) # Á∞°ÂñÆÁ∑öÊÄßÂµåÂÖ•\n",
    "    positional_encoding_macro = layers.LayerNormalization(epsilon=1e-6)(embedding_macro) # Á∞°ÂñÆ‰ΩçÁΩÆÁ∑®Á¢º - Ê≠§ËôïÁ∞°Âåñ\n",
    "\n",
    "    x_macro = positional_encoding_macro\n",
    "    for _ in range(num_transformer_layers):\n",
    "        attention_output_macro = layers.MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x_macro, x_macro)\n",
    "        attention_output_macro = layers.Dropout(0.1)(attention_output_macro)\n",
    "        out1_macro = layers.Add()([x_macro, attention_output_macro])\n",
    "        out1_macro = layers.LayerNormalization(epsilon=1e-6)(out1_macro)\n",
    "\n",
    "        ffn_macro = layers.Dense(ff_dim, activation=\"relu\")(out1_macro)\n",
    "        ffn_output_macro = layers.Dense(ff_dim)(ffn_macro)\n",
    "        ffn_output_macro = layers.Dropout(0.1)(ffn_output_macro)\n",
    "        x_macro = layers.Add()([out1_macro, ffn_output_macro])\n",
    "        x_macro = layers.LayerNormalization(epsilon=1e-6)(x_macro)\n",
    "\n",
    "    transformer_output_macro = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x_macro) if x_macro.shape[1] is not None else layers.Flatten()(x_macro) # ËôïÁêÜÊôÇÈñìÂ∫èÂàóÊàñÊâÅÂπ≥Ëº∏ÂÖ•\n",
    "\n",
    "\n",
    "    # Êñ∞ËÅûÂΩ±ÈüøÂ∫¶Ëº∏ÂÖ•ÂàÜÊîØ (ÂèØÈÅ∏)\n",
    "    input_news = layers.Input(shape=input_shape_news, name=\"news_input\")\n",
    "    embedding_news = layers.Dense(ff_dim)(input_news) # Á∞°ÂñÆÁ∑öÊÄßÂµåÂÖ•\n",
    "    positional_encoding_news = layers.LayerNormalization(epsilon=1e-6)(embedding_news) # Á∞°ÂñÆ‰ΩçÁΩÆÁ∑®Á¢º - Ê≠§ËôïÁ∞°Âåñ\n",
    "\n",
    "    x_news = positional_encoding_news\n",
    "    for _ in range(num_transformer_layers):\n",
    "        attention_output_news = layers.MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x_news, x_news)\n",
    "        attention_output_news = layers.Dropout(0.1)(attention_output_news)\n",
    "        out1_news = layers.Add()([x_news, attention_output_news])\n",
    "        out1_news = layers.LayerNormalization(epsilon=1e-6)(out1_news)\n",
    "\n",
    "        ffn_news = layers.Dense(ff_dim, activation=\"relu\")(out1_news)\n",
    "        ffn_output_news = layers.Dense(ff_dim)(ffn_news)\n",
    "        ffn_output_news = layers.Dropout(0.1)(ffn_output_news)\n",
    "        x_news = layers.Add()([out1_news, ffn_output_news])\n",
    "        x_news = layers.LayerNormalization(epsilon=1e-6)(x_news)\n",
    "\n",
    "    transformer_output_news = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x_news) if x_news.shape[1] is not None else layers.Flatten()(x_news) # ËôïÁêÜÊôÇÈñìÂ∫èÂàóÊàñÊâÅÂπ≥Ëº∏ÂÖ•\n",
    "\n",
    "\n",
    "    # ÁâπÂæµËûçÂêà\n",
    "    fused_features = layers.concatenate([transformer_output_etf, transformer_output_macro, transformer_output_news])\n",
    "\n",
    "    # Ëº∏Âá∫Â±§ (ÂõûÊ≠∏‰ªªÂãô - È†êÊ∏¨Êº≤Ë∑åÂπÖÂ∫¶)\n",
    "    output_layer = layers.Dense(output_dim, activation='linear', name=\"output\")(fused_features) # Á∑öÊÄßÊøÄÊ¥ªÂáΩÊï∏Áî®ÊñºÂõûÊ≠∏\n",
    "\n",
    "    model = keras.Model(inputs=[input_etf, input_macro, input_news], outputs=output_layer) # ÂÆöÁæ©Â§öËº∏ÂÖ•Ê®°Âûã\n",
    "    return model\n",
    "\n",
    "# 4. ÂÆöÁæ© Macro ÊåáÊ®ô tickers\n",
    "macro_tickers = {\n",
    "    'VIX': '^VIX',\n",
    "    '10Y_Yield': '^TNX',\n",
    "    'USD_Index': 'DX-Y.NYB',\n",
    "    'WTI_Crude': 'CL=F'\n",
    "}\n",
    "\n",
    "# 5. ÁîüÊàêÊ®°Êì¨Êï∏Êìö\n",
    "num_samples = 1000\n",
    "num_etfs = 5\n",
    "num_macro_features = len(macro_tickers)\n",
    "num_news_features = 3 # ÂÅáË®≠Êúâ 3 ÂÄãÊñ∞ËÅûÂΩ±ÈüøÂ∫¶ÁâπÂæµ\n",
    "etf_data, macro_data_df, news_data_df = generate_dummy_data(num_samples, num_etfs, num_macro_features, num_news_features)\n",
    "\n",
    "# 6. Ë≥áÊñôÈ†êËôïÁêÜ\n",
    "etf_data_processed, etf_scaler = preprocess_etf_data(etf_data)\n",
    "macro_data_processed, macro_scaler = preprocess_macro_data(macro_data_df)\n",
    "news_data_processed, news_scaler = preprocess_news_data(news_data_df)\n",
    "\n",
    "# 7. Ê∫ñÂÇôÊ®°ÂûãËº∏ÂÖ• (‰ª• ETF_0 ÁÇ∫‰æãÔºå‰∏¶‰∏îÁ∞°ÂåñÊôÇÈñìÂ∫èÂàóËôïÁêÜÔºåÁõ¥Êé•‰ΩøÁî®ÊâÄÊúâÊôÇÈñìÈªûÁöÑË≥áÊñô‰ΩúÁÇ∫Ëº∏ÂÖ•)\n",
    "etf_symbol_to_predict = 'ETF_0'\n",
    "etf_input_data = etf_data_processed[etf_data_processed['ETF'] == etf_symbol_to_predict].drop(['Date', 'ETF', 'Target_Next_Week_Return', 'Direction'], axis=1).values\n",
    "macro_input_data = macro_data_processed\n",
    "news_input_data = news_data_processed\n",
    "\n",
    "# 8. Ê∫ñÂÇôÁõÆÊ®ôËÆäÊï∏ (Target - ETF_0 ÁöÑ‰∏ãÈÄ±Â†±ÈÖ¨Áéá)\n",
    "target_data = etf_data_processed[etf_data_processed['ETF'] == etf_symbol_to_predict]['Target_Next_Week_Return'].values\n",
    "\n",
    "# 9. Ë™øÊï¥Ëº∏ÂÖ•ÂΩ¢ÁãÄ (ÂÅáË®≠Ëº∏ÂÖ•ÊòØ‰∫åÁ∂≠ÁöÑÔºåËã•Ë¶ÅËôïÁêÜÊôÇÈñìÂ∫èÂàóÔºåÈúÄË¶ÅË™øÊï¥ÂΩ¢ÁãÄÁÇ∫‰∏âÁ∂≠Ôºå‰æãÂ¶Ç (samples, timesteps, features))\n",
    "input_shape_etf = (etf_input_data.shape[1],) # (features)\n",
    "input_shape_macro = (macro_input_data.shape[1],) # (features)\n",
    "input_shape_news = (news_input_data.shape[1],) # (features)\n",
    "\n",
    "raise KeyboardInterrupt\n",
    "\n",
    "# 10. ÂâµÂª∫ Transformer Ê®°Âûã\n",
    "model = create_transformer_encoder_model(input_shape_etf, input_shape_macro, input_shape_news)\n",
    "\n",
    "# 11. Á∑®Ë≠ØÊ®°Âûã\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse']) # ÂõûÊ≠∏‰ªªÂãô‰ΩøÁî® MSE Âíå MAE\n",
    "\n",
    "# 12. Ê®°ÂûãÊëòË¶Å\n",
    "model.summary()\n",
    "\n",
    "# 13. Ë®ìÁ∑¥Ê®°Âûã (Á∞°ÂåñÁ§∫‰æãÔºåÂØ¶ÈöõÊáâÁî®‰∏≠ÈúÄË¶ÅÂäÉÂàÜË®ìÁ∑¥ÈõÜ„ÄÅÈ©óË≠âÈõÜ„ÄÅÊ∏¨Ë©¶ÈõÜ)\n",
    "history = model.fit(\n",
    "    x = {\"etf_input\": etf_input_data, \"macro_input\": macro_input_data, \"news_input\": news_input_data},\n",
    "    y = target_data,\n",
    "    epochs=10, # ÂØ¶ÈöõË®ìÁ∑¥ÈúÄË¶ÅÊõ¥Â§ö epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2 # Á∞°ÂåñÈ©óË≠âÈõÜË®≠ÂÆö\n",
    ")\n",
    "\n",
    "# 14. Ë©ï‰º∞Ê®°Âûã (Âú®Ê∏¨Ë©¶ÈõÜ‰∏äË©ï‰º∞ÔºåÈÄôË£°Á∞°ÂåñÁÇ∫‰ΩøÁî®È©óË≠âÈõÜË©ï‰º∞)\n",
    "loss, mae, mse = model.evaluate(\n",
    "    x = {\"etf_input\": etf_input_data[-200:], \"macro_input\": macro_input_data[-200:], \"news_input\": news_input_data[-200:]}, # ‰ΩøÁî®ÊúÄÂæå 200 Á≠ÜË≥áÊñô‰ΩúÁÇ∫Á∞°ÂåñÈ©óË≠â\n",
    "    y = target_data[-200:]\n",
    ")\n",
    "print(f\"Validation Loss: {loss}, MAE: {mae}, MSE: {mse}\")\n",
    "\n",
    "# 15. ‰ΩøÁî®Ê®°ÂûãÈÄ≤Ë°åÈ†êÊ∏¨ (Á∞°ÂåñÁ§∫‰æãÔºå‰ΩøÁî®ÊúÄÂæå‰∏ÄÁ≠ÜË≥áÊñôÈÄ≤Ë°åÈ†êÊ∏¨)\n",
    "sample_input_etf = etf_input_data[-1:]\n",
    "sample_input_macro = macro_input_data[-1:]\n",
    "sample_input_news = news_input_data[-1:]\n",
    "\n",
    "prediction = model.predict({\"etf_input\": sample_input_etf, \"macro_input\": sample_input_macro, \"news_input\": sample_input_news})\n",
    "print(f\"È†êÊ∏¨ÁöÑ‰∏ãÈÄ±Êº≤Ë∑åÂπÖÂ∫¶: {prediction[0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
